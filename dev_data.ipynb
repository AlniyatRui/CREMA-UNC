{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/playpen/xinyu/shoubin/thermalqa/thermalqa_train.json') as f:\n",
    "    train = json.load(f)\n",
    "with open('/playpen/xinyu/shoubin/thermalqa/thermalqa_val.json') as f:\n",
    "    val = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 36.608,\n",
       " 'video_id': '20221027_9_split3',\n",
       " 'question_id': 1521,\n",
       " 'answer': 'sit desk',\n",
       " 'question': 'What might have happened before this video?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in intersection: 216\n",
      "Number of elements unique to crema_state_dict: 69\n",
      "Number of elements unique to model_param: 1121\n"
     ]
    }
   ],
   "source": [
    "# Find intersection between crema_state_dict and model_param\n",
    "intersection = set(crema_state_dict) & set(model_param)\n",
    "\n",
    "# Find elements unique to crema_state_dict\n",
    "unique_to_crema = set(crema_state_dict) - set(model_param)\n",
    "\n",
    "# Find elements unique to model_param\n",
    "unique_to_model_param = set(model_param) - set(crema_state_dict)\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of elements in intersection: {len(intersection)}\")\n",
    "print(f\"Number of elements unique to crema_state_dict: {len(unique_to_crema)}\")\n",
    "print(f\"Number of elements unique to model_param: {len(unique_to_model_param)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5119\n",
      "8533\n",
      "11946\n",
      "15359\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for i in [15,25,35,45]:\n",
    "    with open(f'/home/xinyuzh/workspace/flex/nextqa/nextqa_annotation/skll/train_0.{i}.json') as f:\n",
    "        data = json.load(f)\n",
    "        print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# with open('/playpen/xinyu/sqa3d/ScanQA_format/SQA_train.json') as f:\n",
    "with open('/home/xinyuzh/workspace/flex/nextqa/nextqa_annotation/val.json') as f:\n",
    "# with open('/playpen/xinyu/musicavqa/avqa-train.json') as f:\n",
    "    nextqa_train_file = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4996"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nextqa_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avqa case: vt + axyz\n",
    "# +0 (1): vt\n",
    "# +1 (4): vta, vtx, vty, vtz\n",
    "# +2 (6): vtax, vtay, vtaz, vtxy, vtyz, vtxz\n",
    "# +3 (4): vtaxy, vtaxz, vtayz, vtxyz\n",
    "# +4 (1): vtaxyz, data ratio = 1/(10+4+2) = 1/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31927"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nextqa_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34132\n",
      "5119\n",
      "8533\n",
      "11946\n",
      "15359\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "print(len(nextqa_train_file))\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "for ratio in 0.15,0.25,0.35,0.45:\n",
    "    # Sample 10% of the data\n",
    "    subset_size = int(len(nextqa_train_file) * ratio)\n",
    "    # subset_size = 100\n",
    "    subset = random.sample(nextqa_train_file, subset_size)\n",
    "    print(len(subset))\n",
    "    # Save the subset to a file\n",
    "    # with open(f'/playpen/xinyu/sqa3d/ScanQA_format/SQA_train_{ratio}.json', 'w') as f:\n",
    "    # with open(f'/playpen/xinyu/sqa3d/ScanQA_format/SQA_train_18.json', 'w') as f:\n",
    "    with open(f'/home/xinyuzh/workspace/flex/nextqa/nextqa_annotation/skll/train_{ratio}.json', 'w') as f:\n",
    "        json.dump(subset, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31927\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "print(len(nextqa_train_file))\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Sample 10% of the data\n",
    "subset_size = int(len(nextqa_train_file) * (1/16))\n",
    "# subset_size = 100\n",
    "subset = random.sample(nextqa_train_file, subset_size)\n",
    "\n",
    "# Save the subset to a file\n",
    "# with open('/playpen/xinyu/sqa3d/ScanQA_format/SQA_train_100.json', 'w') as f:\n",
    "# with open('/home/xinyuzh/workspace/flex/nextqa/nextqa_annotation/train_18.json', 'w') as f:\n",
    "with open(f'/playpen/xinyu/musicavqa/avqa-train-116.json','w') as f:\n",
    "    json.dump(subset, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/xinyuzh/workspace/flex/nextqa/nextqa_annotation/train_subset_100.json') as f:\n",
    "    subset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995\n"
     ]
    }
   ],
   "source": [
    "print(len(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in nextqa_train_file:\n",
    "    for new_Key in ['frame','depth','norm','flow']:\n",
    "        sample[new_Key] = sample['video']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/xinyuzh/workspace/flex/nextqa/nextqa_annotation/train_add_modality.json', 'w') as f:\n",
    "    json.dump(nextqa_train_file, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split NEXTQA train file ['frame','depth','norm'] into 3 groups ['frame','depth'] ['depth','norm'] ['frame','norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11378, 11377, 11377]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "import json\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Create a deep copy of train_file to avoid modifying the original\n",
    "train_file_copy = copy.deepcopy(nextqa_train_file)\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(train_file_copy)\n",
    "\n",
    "# Calculate the size of each group\n",
    "group_size = len(train_file_copy) // 3\n",
    "remainder = len(train_file_copy) % 3\n",
    "\n",
    "# Split the data into 3 groups\n",
    "groups = []\n",
    "start = 0\n",
    "for i in range(3):\n",
    "    end = start + group_size + (1 if i < remainder else 0)\n",
    "    groups.append(train_file_copy[start:end])\n",
    "    start = end\n",
    "\n",
    "# Check the sizes\n",
    "print([len(group) for group in groups])\n",
    "\n",
    "# Save each group to a file\n",
    "for i, group in enumerate(groups):\n",
    "    with open(f'/home/xinyuzh/unites1/nextqa/nextqa_annotation/train_split_{i}.json', 'w') as f:\n",
    "        json.dump(group, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split sqa train file ['pc','frame','depth','norm'] into 3 groups ['pc','frame','depth'] ['frame','depth','norm'] ['pc','depth','norm'] ['frame','depth','norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6656, 6656, 6656, 6655]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "import json\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Create a deep copy of train_file to avoid modifying the original\n",
    "train_file_copy = copy.deepcopy(train_file)\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(train_file_copy)\n",
    "\n",
    "# Calculate the size of each group\n",
    "group_size = len(train_file_copy) // 4\n",
    "remainder = len(train_file_copy) % 4\n",
    "\n",
    "# Split the data into 4 groups\n",
    "groups = []\n",
    "start = 0\n",
    "for i in range(4):\n",
    "    end = start + group_size + (1 if i < remainder else 0)\n",
    "    groups.append(train_file_copy[start:end])\n",
    "    start = end\n",
    "\n",
    "# Check the sizes\n",
    "print([len(group) for group in groups])\n",
    "\n",
    "# Save each group to a file\n",
    "for i, group in enumerate(groups):\n",
    "    with open(f'/home/xinyuzh/workspace/flex/CREMA/ScanQA_format/SQA_train_split_{i}.json', 'w') as f:\n",
    "        json.dump(group, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crema",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
